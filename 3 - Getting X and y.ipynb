{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Getting X and y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run this cell to download the data and helper files. { display-mode: \"form\" }\n",
    "!pip install -U wget\n",
    "!rm -rf data.zip data lib\n",
    "!mkdir lib\n",
    "\n",
    "import wget\n",
    "wget.download('https://github.com/shengpu1126/BDSI2019-ML/raw/master/lib/config.yaml', 'lib/config.yaml')\n",
    "wget.download('https://github.com/shengpu1126/BDSI2019-ML/raw/master/lib/helper.py', 'lib/helper.py')\n",
    "wget.download('https://github.com/shengpu1126/BDSI2019-ML/raw/master/data.zip', 'data.zip')\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lib.helper import load_data, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features for the first 2500 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From yesterday :)\n",
    "def generate_feature_vector(df):\n",
    "    \"\"\"\n",
    "    Reads a dataframe containing all measurements for a single patient\n",
    "    within the first 48 hours of the ICU admission, and convert it into\n",
    "    a feature vector.\n",
    "    \n",
    "    Args:\n",
    "        df: pd.Dataframe, with columns [Time, Variable, Value]\n",
    "    \n",
    "    Returns:\n",
    "        a python dictionary of format {feature_name: feature_value}\n",
    "        for example, {'Age': 32, 'Gender': 0, 'mean_HR': 84, ...}\n",
    "    \"\"\"\n",
    "    static_variables = config['invariant']\n",
    "    timeseries_variables = config['timeseries']\n",
    "\n",
    "    # Replace unknow values\n",
    "    df = df.replace({-1: np.nan})\n",
    "    \n",
    "    # Split time invariant and time series\n",
    "    static, timeseries = df.iloc[0:5], df.iloc[5:]\n",
    "    static = static.pivot('Time', 'Variable', 'Value')\n",
    "\n",
    "    feature_dict = static.iloc[0].to_dict()\n",
    "    for variable in timeseries_variables:\n",
    "        measurements = timeseries[timeseries['Variable'] == variable]['Value']\n",
    "        feature_dict['mean_' + variable] = np.mean(measurements)\n",
    "    \n",
    "    return feature_dict\n",
    "\n",
    "# Load the dataset\n",
    "# `raw_data` is a dictionary mapping patient ID to the data associated with that patient\n",
    "raw_data, df_labels = load_data(N=2500)\n",
    "features = [generate_feature_vector(df) for _, df in tqdm(sorted(raw_data.items()), desc='Generating feature vectors')]\n",
    "\n",
    "df_features = pd.DataFrame(features).sort_index(axis=1)\n",
    "feature_names = df_features.columns.tolist()\n",
    "X, y = df_features.values, df_labels['In-hospital_death'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is X?\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just so you know pd.DataFrame can be used to display a matrix nicely\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to implement...\n",
    "\n",
    "- `impute_missing_values(X)`: <br> Given a feature matrix `X` (where each row corresponds to a patient admission and each column a feature) with missing values, we consider each feature column independently. For each column, we impute the missing values by replacing it with the mean value of the observed values in that column. Hint: use `np.nanmean()` to compute the mean of an `np.array` with `np.nan` values. \n",
    "- `normalize_feature_matrix(X)`: <br> Notice that many of these feature values lie on very different scales. Here, we will address this issue by nnormalizing the features. Given a feature matrix X (where each row corre- sponds to a patient admission and each column a feature) now without any missing values, we use the following formula to normalize each feature column xd to have range between 0 and 1:\n",
    "$$\\tilde{x}_d = \\frac{(x_d - \\min)}{(\\max - \\min)} \\text{, where } \\min = \\min_{i=1\\dots n} x_d^{(i)} \\text{, and } \\max = \\max_{i=1\\dots n} x_d^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values_by_mean(X):\n",
    "    \"\"\"\n",
    "    For each feature column, impute missing values (np.nan) with the \n",
    "    population mean for that feature.\n",
    "    \n",
    "    Args:\n",
    "        X: np.array, shape (N, d). X could contain missing values\n",
    "    Returns:\n",
    "        X: np.array, shape (N, d). X does not contain any missing values\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    return X\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalize_feature_matrix(X):\n",
    "    \"\"\"\n",
    "    For each feature column, normalize all values to range [0, 1].\n",
    "\n",
    "    Args:\n",
    "        X: np.array, shape (N, d).\n",
    "    Returns:\n",
    "        X: np.array, shape (N, d). Values are normalized per column.\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputed = impute_missing_values_by_mean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is X_imputed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: 0/1 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = normalize_feature_matrix(X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is X_normalized?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# What's the average feature vector (after mean imputation and 0/1 normalization)? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "- Implement both functions without using for-loops (because for-loops in python are slow). \n",
    "- Implement each function with one line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge+\n",
    "\n",
    "References:\n",
    "- scikit-learn – \"imputation of missing values\": https://scikit-learn.org/stable/modules/impute.html\n",
    "- Imputation techniques with examples: https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n",
    "\n",
    "Implement one (or more) of the other imputation techniques, and compare it with mean imputation in terms of:\n",
    "- runtime/efficiency, \n",
    "- resultant feature distribution, \n",
    "- what assumptions does each technique make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values_by_????(X):\n",
    "    \"\"\"\n",
    "    Impute missing values (np.nan) using \n",
    "    your choice of imputation technique. \n",
    "    \n",
    "    Args:\n",
    "        X: np.array, shape (N, d). X could contain missing values\n",
    "    Returns:\n",
    "        X: np.array, shape (N, d). X does not contain any missing values\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp_mean = impute_missing_values_by_mean(X)\n",
    "X_imp_???? = impute_missing_values_by_????(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge++\n",
    "\n",
    "References:\n",
    "- scikit-learn – \"preprocessing\": https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e\n",
    "\n",
    "Try out other feature scaling/normalization/transformation techniques, and compare it with 0/1 normalization.\n",
    "- Range of resultant feature values\n",
    "- What assumptions might a model make about its input features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feature_matrix_by_???(X):\n",
    "    \"\"\"\n",
    "    For each feature column, apply your chosen \"normalization\".\n",
    "\n",
    "    Args:\n",
    "        X: np.array, shape (N, d).\n",
    "    Returns:\n",
    "        X: np.array, shape (N, d). Values are normalized per column.\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
