{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U wget\n",
    "!rm -rf data.zip data lib\n",
    "!mkdir lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "wget.download('https://github.com/shengpu1126/BDSI2019-ML/raw/master/lib/config.yaml', 'lib/config.yaml')\n",
    "wget.download('https://github.com/shengpu1126/BDSI2019-ML/raw/master/lib/helper.py', 'lib/helper.py')\n",
    "wget.download('https://github.com/shengpu1126/BDSI2019-ML/raw/master/data.zip', 'data.zip')\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Feature Extraction\n",
    "\n",
    "The goal of feature extraction is to transform each patient’s raw data into a $d$-dimensional feature vector, so that we can learn an machine learning model. Here, we will summarize each time-varying variable, by taking the mean. See **Figure 1** for an illustration.\n",
    "\n",
    "![title](lib/EHR_feature.png)\n",
    "\n",
    "**Figure 1.** Transforming EHR data into a feature vector. `Age` and `Height` are time-invariant variables, each of which is encoded as a separate feature. For this patient, the feature `Age` has its original value, while the feature `Height` is `np.nan` since it is unknown (−1). `HR`, `Temp` and `RespRate` are time-varying variables. Here, we will encode each variable by its mean. The feature `mean_HR` contains the mean heart rate measurements, whereas `mean_RespeRate` is `np.nan` because no respiratory rate measurements were recorded for this patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.helper import load_data, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to implement...\n",
    "\n",
    "- `generate_feature_vector(df)`: <br> For the time-invariant variables, use the raw values. Replace unknown observations (−1) with undefined (use `np.nan`), and name these features with the original variable names. For each time-varying variable, compute the mean of all measurements for that variable. If no measurement exists for a variable, the mean is also undefined (use `np.nan`). Name these features as `mean_{Variable}` for each variable. For example, the variable `HR` would correspond to the feature with name `mean_HR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vector(df):\n",
    "    \"\"\"\n",
    "    Reads a dataframe containing all measurements for a single patient\n",
    "    within the first 48 hours of the ICU admission, and convert it into\n",
    "    a feature vector.\n",
    "    \n",
    "    Args:\n",
    "        df: pd.Dataframe, with columns [Time, Variable, Value]\n",
    "    \n",
    "    Returns:\n",
    "        a python dictionary of format {feature_name: feature_value}\n",
    "        for example, {'Age': 32, 'Gender': 0, 'mean_HR': 84, ...}\n",
    "    \"\"\"\n",
    "    static_variables = config['static']\n",
    "    timeseries_variables = config['timeseries']\n",
    "\n",
    "    # Replace unknown values\n",
    "    df = df.replace({-1: np.nan})\n",
    "    \n",
    "    ## TODO: implement this function\n",
    "    feature_dict = {}\n",
    "    \n",
    "    \n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# `raw_data` is a dictionary mapping patient ID to the data associated with that patient\n",
    "raw_data, df_labels = load_data(N=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = sorted(raw_data.keys())\n",
    "ID = IDs[0]\n",
    "df = raw_data[ID]\n",
    "df_i = generate_feature_vector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ID)\n",
    "df_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features for the first 2500 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [generate_feature_vector(df) for _, df in tqdm(sorted(raw_data.items()), desc='Generating feature vectors')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(features).sort_index(axis=1)\n",
    "feature_names = df_features.columns.tolist()\n",
    "X, y = df_features.values, df_labels['In-hospital_death'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:\n",
    "# Report the dimensionality of feature vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:\n",
    "# What are the names of each feature? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:\n",
    "# For each feature, what is the fraction of patients having that feature missing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:\n",
    "# Report the average value of each feature (considering only recorded non-missing values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "1. Read the [documentation](https://physionet.org/challenge/2012/\\#general-descriptors) on the variable `ICUType`, and reflect on the current feature representation of this variable. What does such a representation imply, when using a linear classifier? How else might you represent this variable (as possibly more than one feature)?\n",
    "2. Here we only consider the mean of the numerical variables. What limitations are associated with this representation? What other summary statistics could be useful?\n",
    "3. How should we handle missing values? \n",
    "4. Notice that features could have values in different orders of magnitudes (age between 18 and 100 while gender is 0 or 1). How should we handle these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
